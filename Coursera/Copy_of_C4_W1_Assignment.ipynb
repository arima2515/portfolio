{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of C4_W1_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXdEnmVvXdUa"
      },
      "source": [
        "# Train Your Own Model and Serve It With TensorFlow Serving\n",
        "\n",
        "In this notebook, you will train a neural network to classify images of handwritten digits from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. You will then save the trained model, and serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSfb9Qd5XdFL"
      },
      "source": [
        "**Warning: This notebook is designed to be run in a Google Colab only**.  It installs packages on the system and requires root access. If you want to run it in a local Jupyter notebook, please proceed with caution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Q8bkjeYTl-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8r89tTPI-Kb"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGFJmWjrKttn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38150b34-b300-4c46-917e-dbb1a4b2c118"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â€¢ Using TensorFlow Version: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq-214o8SNt0"
      },
      "source": [
        "## Import the MNIST Dataset\n",
        "\n",
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains 70,000 grayscale images of the digits 0 through 9. The images show individual digits at a low resolution (28 by 28 pixels). \n",
        "\n",
        "Even though these are really images, we will load them as NumPy arrays and not as binary image objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIT-qX0QzLo-"
      },
      "source": [
        "# EXERCISE: Scale the values of the arrays below to be between 0.0 and 1.0.\n",
        "train_images = train_images / 255. # YOUR CODE HERE\n",
        "test_images = test_images / 255.# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIDGu-EEzdKb"
      },
      "source": [
        "In the cell below use the `.reshape` method to resize the arrays to the following sizes:\n",
        "\n",
        "```python\n",
        "train_images.shape: (60000, 28, 28, 1)\n",
        "test_images.shape: (10000, 28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsIxeG6BzN4t"
      },
      "source": [
        "# EXERCISE: Reshape the arrays below.\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1) # YOUR CODE HERE\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUw8ZxigB1Nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ac0df4-1b24-41cd-fd02-d1555766cda1"
      },
      "source": [
        "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
        "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_images.shape: (60000, 28, 28, 1), of float64\n",
            "test_images.shape: (10000, 28, 28, 1), of float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcR0OKbOSj0c"
      },
      "source": [
        "## Look at a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQMs4v_oSo9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e60f3fe-09bd-42fc-a965-f393861f0f97"
      },
      "source": [
        "idx = 42\n",
        "\n",
        "plt.imshow(test_images[idx].reshape(28,28), cmap=plt.cm.binary)\n",
        "plt.title('True Label: {}'.format(test_labels[idx]), fontdict={'size': 16})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn_-9OsPYnDp"
      },
      "source": [
        "## Build a Model\n",
        "\n",
        "In the cell below build a `tf.keras.Sequential` model that can be used to classify the images of the MNIST dataset. Feel free to use the simplest possible CNN. Make sure your model has the correct `input_shape` and the correct number of output units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgMgJJynMbVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e30fcb-2020-4a12-a8dc-7acf4b5cec46"
      },
      "source": [
        "# EXERCISE: Create a model.\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3,\n",
        "                               strides=2, activation='relu', name='Conv1'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
        "                             \n",
        "                      \n",
        "\n",
        "\n",
        "])# YOUR CODE HERE\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 13, 13, 8)         80        \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1352)              0         \n",
            "                                                                 \n",
            " Softmax (Dense)             (None, 10)                13530     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,610\n",
            "Trainable params: 13,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLzXnZT1YvS6"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "In the cell below configure your model for training using the `adam` optimizer, `sparse_categorical_crossentropy` as the loss, and `accuracy` for your metrics. Then train the model for the given number of epochs, using the `train_images` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTNN0ANGgA36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b77d9e-d249-4026-8de5-8e2ba0ab6906"
      },
      "source": [
        "# EXERCISE: Configure the model for training.\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# EXERCISE: Train the model.\n",
        "history = model.fit(train_images, train_labels, epochs=epochs, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 6s - loss: 0.3319 - accuracy: 0.9096 - 6s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 5s - loss: 0.1407 - accuracy: 0.9600 - 5s/epoch - 3ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 5s - loss: 0.1066 - accuracy: 0.9699 - 5s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 4s - loss: 0.0889 - accuracy: 0.9746 - 4s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 4s - loss: 0.0788 - accuracy: 0.9769 - 4s/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er_vrDhf4qu5"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMD387B93f2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ded9344-9c1c-41f6-e763-f88573c33128"
      },
      "source": [
        "# EXERCISE: Evaluate the model on the test images.\n",
        "results_eval = model.evaluate(test_images, test_labels)# YOUR CODE HERE\n",
        "\n",
        "for metric, value in zip(model.metrics_names, results_eval):\n",
        "    print(metric + ': {:.3}'.format(value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9756\n",
            "loss: 0.0794\n",
            "accuracy: 0.976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmT8M1Yx5y"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uFDoDW_7HX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9944d1d-48b9-4233-f735-e0a0c11bf4ab"
      },
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Already saved a model, cleaning up\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Conv1_input with unsupported characters which will be renamed to conv1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "export_path = /tmp/1\n",
            "total 88\n",
            "drwxr-xr-x 2 root root  4096 Apr 26 13:51 assets\n",
            "-rw-r--r-- 1 root root  8105 Apr 26 13:51 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 73272 Apr 26 13:51 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 Apr 26 13:51 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KziE3e9tY-hH"
      },
      "source": [
        "## Examine Your Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4GDF_aYtfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8931863-7be4-4c2e-d6ad-08bda5a4d0f0"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['Conv1_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_Conv1_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['Softmax'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsDTdBGHZAzo"
      },
      "source": [
        "## Add TensorFlow Serving Distribution URI as a Package Source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWg9X2QHlbGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4af9bc-a0f5-4fee-ba3e-5a38835a98f7"
      },
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0   4271      0 --:--:-- --:--:-- --:--:--  4265\n",
            "OK\n",
            "Hit:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,732 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [909 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,496 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [942 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,167 kB]\n",
            "Fetched 9,497 kB in 3s (2,936 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l5XkzqNZNBU"
      },
      "source": [
        "## Install TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygwa9AgRloYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7f222e-3da1-41f2-c41e-ba41e85c3821"
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tensorflow-model-server is already the newest version (2.8.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd_PobAKZWW8"
      },
      "source": [
        "## Run the TensorFlow Model Server\n",
        "\n",
        "You will now launch the TensorFlow model server with a bash script. In the cell below use the following parameters when running the TensorFlow model server:\n",
        "\n",
        "* `rest_api_port`: Use port `8501` for your requests.\n",
        "\n",
        "\n",
        "* `model_name`: Use `digits_model` as your model name. \n",
        "\n",
        "\n",
        "* `model_base_path`: Use the environment variable `MODEL_DIR` defined below as the base path to the saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUgp3vUdU5GS"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJDhHNJVnaLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a7f106-25e5-4473-aebe-affd0ba2cb21"
      },
      "source": [
        "# EXERCISE: Fill in the missing code below.\n",
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=digits_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxbeiOCUUs2z"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mUrIWVRZdNu"
      },
      "source": [
        "## Create JSON Object with Test Images\n",
        "\n",
        "In the cell below construct a JSON object and use the first three images of the testing set (`test_images`) as your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dsD7KQG1m-R"
      },
      "source": [
        "# EXERCISE: Create JSON Object\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()})# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRdyPl4CZ5CU"
      },
      "source": [
        "## Make Inference Request\n",
        "\n",
        "In the cell below, send a predict request as a POST to the server's REST endpoint, and pass it your test data. You should ask the server to give you the latest version of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGvFyuIzW6n6"
      },
      "source": [
        "# EXERCISE: Fill in the code below\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://192.168.1.1:8501/v1/models/digits_model:predict', data=data, headers=headers)\n",
        "    \n",
        "predictions = json.loads(json_response.text)['predictions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtrFMts_ackX"
      },
      "source": [
        "## Plot Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxQzj34aiDz1"
      },
      "source": [
        "plt.figure(figsize=(10,15))\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(test_images[i].reshape(28,28), cmap = plt.cm.binary)\n",
        "    plt.axis('off')\n",
        "    color = 'green' if np.argmax(predictions[i]) == test_labels[i] else 'red'\n",
        "    plt.title('Prediction: {}\\nTrue Label: {}'.format(np.argmax(predictions[i]), test_labels[i]), color=color)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}