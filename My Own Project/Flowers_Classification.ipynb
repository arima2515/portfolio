{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuh6clApmfnP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "input_shape = (150, 150, 3)\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O70xBHoCnGGZ"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "train_path = os.getcwd() + \"/drive/MyDrive/Dataset/flowers/train\"\n",
        "val_path = os.getcwd() + \"/drive/MyDrive/Dataset/flowers/val\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ycGYWuRnLZQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   featurewise_center=False,\n",
        "                                   samplewise_center=False,\n",
        "                                   featurewise_std_normalization=False,\n",
        "                                   samplewise_std_normalization=False,\n",
        "                                   rotation_range=10,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   vertical_flip=False,\n",
        "                                   zca_whitening=False\n",
        "                                   )\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w-YXMQlnMYa",
        "outputId": "86429909-691d-4c27-8f3b-396c43b2fe82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3237 images belonging to 5 classes.\n",
            "Found 1080 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_path,\n",
        "                                                    target_size=input_shape[:-1],\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "val_generator = val_datagen.flow_from_directory(val_path,\n",
        "                                                    target_size=input_shape[:-1],\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "num_class = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3XFWp5anR75"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJCZRUTOnVx-"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRhBab20nYlo",
        "outputId": "8af8d229-9149-4368-813e-a412b06a6cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "203/203 [==============================] - 894s 4s/step - loss: 1.2669 - accuracy: 0.4520 - val_loss: 0.9873 - val_accuracy: 0.6259\n",
            "Epoch 2/100\n",
            "203/203 [==============================] - 136s 669ms/step - loss: 1.0350 - accuracy: 0.5833 - val_loss: 0.9978 - val_accuracy: 0.5972\n",
            "Epoch 3/100\n",
            "203/203 [==============================] - 138s 680ms/step - loss: 0.9572 - accuracy: 0.6284 - val_loss: 1.0225 - val_accuracy: 0.6185\n",
            "Epoch 4/100\n",
            "203/203 [==============================] - 135s 665ms/step - loss: 0.9082 - accuracy: 0.6420 - val_loss: 0.8508 - val_accuracy: 0.6556\n",
            "Epoch 5/100\n",
            "203/203 [==============================] - 135s 664ms/step - loss: 0.8691 - accuracy: 0.6713 - val_loss: 0.7901 - val_accuracy: 0.6972\n",
            "Epoch 6/100\n",
            "203/203 [==============================] - 135s 662ms/step - loss: 0.8436 - accuracy: 0.6750 - val_loss: 0.7882 - val_accuracy: 0.7037\n",
            "Epoch 7/100\n",
            "203/203 [==============================] - 134s 660ms/step - loss: 0.8257 - accuracy: 0.6973 - val_loss: 0.7638 - val_accuracy: 0.7083\n",
            "Epoch 8/100\n",
            "203/203 [==============================] - 134s 660ms/step - loss: 0.7816 - accuracy: 0.7044 - val_loss: 0.7456 - val_accuracy: 0.7157\n",
            "Epoch 9/100\n",
            "203/203 [==============================] - 134s 661ms/step - loss: 0.7817 - accuracy: 0.6935 - val_loss: 0.7530 - val_accuracy: 0.7065\n",
            "Epoch 10/100\n",
            "203/203 [==============================] - 136s 670ms/step - loss: 0.7509 - accuracy: 0.7093 - val_loss: 0.7688 - val_accuracy: 0.6926\n",
            "Epoch 11/100\n",
            "203/203 [==============================] - 135s 662ms/step - loss: 0.7269 - accuracy: 0.7121 - val_loss: 0.7919 - val_accuracy: 0.6861\n",
            "Epoch 12/100\n",
            "203/203 [==============================] - 134s 660ms/step - loss: 0.7086 - accuracy: 0.7297 - val_loss: 0.7357 - val_accuracy: 0.7370\n",
            "Epoch 13/100\n",
            "203/203 [==============================] - 133s 656ms/step - loss: 0.6932 - accuracy: 0.7439 - val_loss: 0.6908 - val_accuracy: 0.7407\n",
            "Epoch 14/100\n",
            "203/203 [==============================] - 132s 651ms/step - loss: 0.6615 - accuracy: 0.7507 - val_loss: 0.6714 - val_accuracy: 0.7435\n",
            "Epoch 15/100\n",
            "203/203 [==============================] - 134s 659ms/step - loss: 0.6642 - accuracy: 0.7451 - val_loss: 0.6343 - val_accuracy: 0.7444\n",
            "Epoch 16/100\n",
            "203/203 [==============================] - 134s 659ms/step - loss: 0.6460 - accuracy: 0.7559 - val_loss: 0.6671 - val_accuracy: 0.7546\n",
            "Epoch 17/100\n",
            "203/203 [==============================] - 134s 658ms/step - loss: 0.6349 - accuracy: 0.7646 - val_loss: 0.7014 - val_accuracy: 0.7481\n",
            "Epoch 18/100\n",
            "203/203 [==============================] - 133s 656ms/step - loss: 0.6406 - accuracy: 0.7587 - val_loss: 0.6621 - val_accuracy: 0.7565\n",
            "Epoch 19/100\n",
            "203/203 [==============================] - 134s 657ms/step - loss: 0.5927 - accuracy: 0.7788 - val_loss: 0.6639 - val_accuracy: 0.7657\n",
            "Epoch 20/100\n",
            "203/203 [==============================] - 134s 657ms/step - loss: 0.6044 - accuracy: 0.7736 - val_loss: 0.7215 - val_accuracy: 0.7472\n",
            "Epoch 21/100\n",
            "203/203 [==============================] - 133s 653ms/step - loss: 0.5708 - accuracy: 0.7856 - val_loss: 0.6182 - val_accuracy: 0.7667\n",
            "Epoch 22/100\n",
            "203/203 [==============================] - 133s 654ms/step - loss: 0.5456 - accuracy: 0.7961 - val_loss: 0.7562 - val_accuracy: 0.7370\n",
            "Epoch 23/100\n",
            "203/203 [==============================] - 133s 656ms/step - loss: 0.5607 - accuracy: 0.7828 - val_loss: 0.6433 - val_accuracy: 0.7778\n",
            "Epoch 24/100\n",
            "203/203 [==============================] - 134s 657ms/step - loss: 0.5431 - accuracy: 0.7977 - val_loss: 0.7184 - val_accuracy: 0.7667\n",
            "Epoch 25/100\n",
            "203/203 [==============================] - 133s 656ms/step - loss: 0.5288 - accuracy: 0.8001 - val_loss: 0.6572 - val_accuracy: 0.7796\n",
            "Epoch 26/100\n",
            "203/203 [==============================] - 134s 661ms/step - loss: 0.5264 - accuracy: 0.8051 - val_loss: 0.6253 - val_accuracy: 0.7685\n",
            "Epoch 27/100\n",
            "203/203 [==============================] - 135s 666ms/step - loss: 0.5167 - accuracy: 0.8004 - val_loss: 0.6154 - val_accuracy: 0.7824\n",
            "Epoch 28/100\n",
            "203/203 [==============================] - 136s 670ms/step - loss: 0.4970 - accuracy: 0.8171 - val_loss: 0.6432 - val_accuracy: 0.7787\n",
            "Epoch 29/100\n",
            "203/203 [==============================] - 135s 666ms/step - loss: 0.4851 - accuracy: 0.8248 - val_loss: 0.6361 - val_accuracy: 0.7796\n",
            "Epoch 30/100\n",
            "203/203 [==============================] - 133s 652ms/step - loss: 0.4745 - accuracy: 0.8230 - val_loss: 0.6995 - val_accuracy: 0.7694\n",
            "Epoch 31/100\n",
            "203/203 [==============================] - 132s 650ms/step - loss: 0.4579 - accuracy: 0.8273 - val_loss: 0.6963 - val_accuracy: 0.7704\n",
            "Epoch 32/100\n",
            "203/203 [==============================] - 132s 647ms/step - loss: 0.4854 - accuracy: 0.8285 - val_loss: 0.6886 - val_accuracy: 0.7630\n",
            "Epoch 33/100\n",
            "203/203 [==============================] - 131s 647ms/step - loss: 0.4467 - accuracy: 0.8319 - val_loss: 0.6753 - val_accuracy: 0.7898\n",
            "Epoch 34/100\n",
            "203/203 [==============================] - 131s 646ms/step - loss: 0.4444 - accuracy: 0.8329 - val_loss: 0.6966 - val_accuracy: 0.7759\n",
            "Epoch 35/100\n",
            "203/203 [==============================] - 131s 647ms/step - loss: 0.4206 - accuracy: 0.8418 - val_loss: 0.6273 - val_accuracy: 0.8056\n",
            "Epoch 36/100\n",
            "203/203 [==============================] - 131s 646ms/step - loss: 0.4088 - accuracy: 0.8455 - val_loss: 0.6879 - val_accuracy: 0.7843\n",
            "Epoch 37/100\n",
            "203/203 [==============================] - 131s 646ms/step - loss: 0.4035 - accuracy: 0.8533 - val_loss: 0.6611 - val_accuracy: 0.7861\n",
            "Epoch 38/100\n",
            "203/203 [==============================] - 131s 646ms/step - loss: 0.3967 - accuracy: 0.8520 - val_loss: 0.6561 - val_accuracy: 0.7824\n",
            "Epoch 39/100\n",
            "203/203 [==============================] - 132s 649ms/step - loss: 0.4146 - accuracy: 0.8480 - val_loss: 0.6512 - val_accuracy: 0.7713\n",
            "Epoch 40/100\n",
            "203/203 [==============================] - 132s 652ms/step - loss: 0.3975 - accuracy: 0.8548 - val_loss: 0.6519 - val_accuracy: 0.7824\n",
            "Epoch 41/100\n",
            "203/203 [==============================] - 132s 650ms/step - loss: 0.3974 - accuracy: 0.8560 - val_loss: 0.7289 - val_accuracy: 0.7630\n",
            "Epoch 42/100\n",
            "203/203 [==============================] - 132s 650ms/step - loss: 0.3830 - accuracy: 0.8613 - val_loss: 0.6836 - val_accuracy: 0.7944\n",
            "Epoch 43/100\n",
            "203/203 [==============================] - 132s 649ms/step - loss: 0.3802 - accuracy: 0.8588 - val_loss: 0.6334 - val_accuracy: 0.7861\n",
            "Epoch 44/100\n",
            "203/203 [==============================] - 132s 648ms/step - loss: 0.3720 - accuracy: 0.8591 - val_loss: 0.7197 - val_accuracy: 0.7889\n",
            "Epoch 45/100\n",
            "203/203 [==============================] - 132s 650ms/step - loss: 0.3834 - accuracy: 0.8622 - val_loss: 0.7350 - val_accuracy: 0.7861\n",
            "Epoch 46/100\n",
            "203/203 [==============================] - 132s 648ms/step - loss: 0.3609 - accuracy: 0.8684 - val_loss: 0.8386 - val_accuracy: 0.7593\n",
            "Epoch 47/100\n",
            "203/203 [==============================] - 133s 653ms/step - loss: 0.3348 - accuracy: 0.8826 - val_loss: 0.7073 - val_accuracy: 0.7815\n",
            "Epoch 48/100\n",
            "203/203 [==============================] - 133s 654ms/step - loss: 0.3412 - accuracy: 0.8764 - val_loss: 0.8279 - val_accuracy: 0.7685\n",
            "Epoch 49/100\n",
            "203/203 [==============================] - 132s 649ms/step - loss: 0.3467 - accuracy: 0.8770 - val_loss: 0.7061 - val_accuracy: 0.8009\n",
            "Epoch 50/100\n",
            "203/203 [==============================] - 131s 646ms/step - loss: 0.3416 - accuracy: 0.8764 - val_loss: 0.6933 - val_accuracy: 0.7824\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='accuracy', mode='max',patience=3)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=100,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(val_generator),\n",
        "        shuffle=True, \n",
        "        verbose = 1,\n",
        "        callbacks =[callbacks])\n",
        "len(history.history['val_loss'])  # Only 4 epochs are run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hd9FwskknaAg",
        "outputId": "1b11cdae-7237-4f07-b127-dc494b2886e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model_sequential.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_sequential.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4sHREoyndO_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  predictions = model.predict_classes(images, batch_size=10)\n",
        "  if(predictions[0]==0):\n",
        "    print(\"Daisy\")\n",
        "  elif(predictions[0]==1):\n",
        "    print(\"Dandelion\")\n",
        "  elif(predictions[0]==2):\n",
        "    print(\"Rose\")\n",
        "  elif(predictions[0]==3):\n",
        "    print(\"Sunflower\")\n",
        "  else:\n",
        "    print(\"Tulip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZp7vtBI0QIL"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wcUeBB60VJ8"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Flowers Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}